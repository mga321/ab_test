{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "This project will assure you have mastered the subjects covered in the statistics lessons.  The hope is to have this project be as comprehensive of these topics as possible.  Good luck!\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability & Cleaning the Data](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these \n",
    "\n",
    "For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "**As you work through this notebook, follow along in the classroom and answer the corresponding quiz questions associated with each question.** The labels for each classroom concept are provided for each question.  This will assure you are on the right track as you work through the project, and you can feel more confident in your final submission meeting the criteria.  As a final check, assure you meet all the criteria on the [RUBRIC](https://review.udacity.com/#!/projects/37e27304-ad47-4eb0-a1ab-8c12f60e43d0/rubric).\n",
    "\n",
    "<a id='probability'></a>\n",
    "## Part I - Probability & Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean and investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique users in the dataset\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of users converted\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times new_page and treatment don't line up\n",
    "treat_and_old = df.query('group == \"treatment\" and landing_page == \"old_page\"')\n",
    "contr_and_new = df.query('group == \"control\" and landing_page == \"new_page\"')\n",
    "\n",
    "temp_df = pd.concat([treat_and_old, contr_and_new], ignore_index=True)\n",
    "temp_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3893 entries, 0 to 3892\n",
      "Data columns (total 5 columns):\n",
      "user_id         3893 non-null int64\n",
      "timestamp       3893 non-null object\n",
      "group           3893 non-null object\n",
      "landing_page    3893 non-null object\n",
      "converted       3893 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# do any of these rows have missing values\n",
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df without the mismatched rows\n",
    "treat_and_new = df.query('group == \"treatment\" and landing_page == \"new_page\"')\n",
    "contr_and_old = df.query('group == \"control\" and landing_page == \"old_page\"')\n",
    "\n",
    "df = pd.concat([treat_and_new, contr_and_old], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double Check all of the correct rows were removed - this should be 0\n",
    "df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many unique user ids there are in df2\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this seems to be one less than the total shape, double check the total shape\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "938    773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "1404   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the rows for the duplicated user id\n",
    "df[df.duplicated(['user_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop one of the rows\n",
    "df.drop(1405, inplace=True)\n",
    "\n",
    "# check the shape to confirm\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute the necessary probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of an individual converting regardless of page\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of conversion given the individual is in the control group\n",
    "df.query('group == \"control\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of conversion given the individual is in the treatment group\n",
    "df.query('group == \"treatment\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability an individual received the new page\n",
    "df.query('landing_page == \"new_page\"').shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above probabilities do NOT provide sufficient evidence to prove that the new page leads to more conversions. The probabilities of 0.1204 and 0.1188 for the control and treatments groups, respectively, are too similar to prove that either group has an increased or decreased conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "## Part II - A/B Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. State our hypotheses\n",
    "\n",
    "Assume the old page is better unless the new page proves to be better.\n",
    "\n",
    ">$H_0: p_{old} \\geq p_{new}$\n",
    ">\n",
    ">$H_1: p_{old} < p_{new}$\n",
    "\n",
    "\n",
    "Therefore our hypotheses are:\n",
    "\n",
    ">$H_0: p_{new} - p_{old} \\leq 0$\n",
    ">\n",
    ">$H_1: p_{new} - p_{old} > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate observed means and observed diff and create sampling distribution from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of only converted column from treatment group\n",
    "# convert to numpy array to use in calculating the mean conversion rate for the new page\n",
    "new_page_converted = df.query('landing_page == \"new_page\"')['converted']\n",
    "new_page_converted = np.array(new_page_converted)\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean conversion rate for treatment group\n",
    "mean_new_page = new_page_converted.mean()\n",
    "mean_new_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of only converted column from control group\n",
    "# convert to numpy array to use in calculating the mean conversion rate for the old page\n",
    "old_page_converted = df.query('landing_page == \"old_page\"')['converted']\n",
    "old_page_converted = np.array(old_page_converted)\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean conversion rate for control group\n",
    "mean_old_page = old_page_converted.mean()\n",
    "mean_old_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate observed difference in conversion rates between treatment and control groups\n",
    "obs_diff = mean_new_page - mean_old_page\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sampling dist from our data\n",
    "p_diffs_sampling_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    sample_new = np.random.choice(new_page_converted, size=df.shape[0], replace=True)\n",
    "    conversion_rate_new = sample_new.mean()\n",
    "    sample_old = np.random.choice(old_page_converted, size=df.shape[0], replace=True)\n",
    "    conversion_rate_old = sample_old.mean()\n",
    "    diff = conversion_rate_new - conversion_rate_old\n",
    "    p_diffs_sampling_dist.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000842042145713862"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the standard deviation of the simulation from our data\n",
    "p_diffs_sampling_dist_std = np.std(p_diffs_sampling_dist)\n",
    "p_diffs_sampling_dist_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulate our null hypothesis values using the standard deviation of the sampling distribution and hypothesized mean diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the null values\n",
    "null_vals = np.random.normal(0, p_diffs_sampling_dist_std, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the simulated null values\n",
    "plt.hist(null_vals)\n",
    "\n",
    "# plot the observed mean diff\n",
    "plt.axvline(obs_diff, c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to know if the new page leads to an increase in conversion rates so we calculate the proportion of\n",
    "# null values above our observed value\n",
    "# because our alternative hypothesis contains > we \"shade\" all null values on --> (this side) of the observed statistic\n",
    "pval = (null_vals > obs_diff).mean()\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large p-value means we fail to reject the null hypothesis. Our threshold for type 1 errors is 0.05 and our computed p-value of 0.9676 is far above our threshold, therefore this is a large p-value and we fail to reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Built-In Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of conversions for each page and total number of individuals for each page\n",
    "convert_old = df.query('landing_page == \"old_page\" and converted == 1').shape[0]\n",
    "convert_new = df.query('landing_page == \"new_page\" and converted == 1').shape[0]\n",
    "n_old = df.query('landing_page == \"old_page\"').shape[0]\n",
    "n_new = df.query('landing_page == \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use stats.proportions_ztest to compute the test statistic and p-value\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative='larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed z_score tells us that our observed statistic is 1.3109 standard deviations from the null mean and our computed p-value of 0.9051 tells us that we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "## Part III - A Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run a logistic regression with ab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>not_ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "1   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "\n",
       "   intercept  ab_page  not_ab_page  \n",
       "0          1        1            0  \n",
       "1          1        1            0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create intercept and dummy variables\n",
    "df['intercept'] = 1\n",
    "df[['ab_page', 'not_ab_page']] = pd.get_dummies(df['landing_page'])\n",
    "\n",
    "# confirm ab_page column 1 for treatment and 0 for control\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "1   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        1  \n",
       "1          1        1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary not_ab_page column\n",
    "df.drop(columns='not_ab_page', inplace=True)\n",
    "\n",
    "# confirm column was dropped\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# create and run the model, then store the results\n",
    "log_mod = sm.Logit(df['converted'], df[['intercept', 'ab_page']])\n",
    "\n",
    "results = log_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 02 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:06:23</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Tue, 02 Apr 2019   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        16:06:23   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the model summary\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value associated with ab_page is 0.190. This p-value differs from the p-value from our hypothesis test because the regression's p-value provides different information.\n",
    "\n",
    "The p-value associated with variables in our logistic regression tells us whether seeing the new page, as opposed to the old page, is a strong predictor of conversion.\n",
    "\n",
    "With a p-value above our threshold of 0.05, our logistic regression shows us that ab_page alone is not a strong predictor of conversion.\n",
    "\n",
    "Should we add other factors into our model?\n",
    "It would be a good idea to add additional factors into our model since ab_page alone is not a strong predictor. However, it is possible that ab_page paired with additional factors is a stronger predictor of conversion. A potential disadvantage to adding factors into our model would be the appearance of multicollinearity if the terms are too closely related to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run a logistic regression with country of residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import countries.csv file\n",
    "countries_df = pd.read_csv('countries.csv')\n",
    "\n",
    "# join the country df with the existing df\n",
    "df_new = countries_df.set_index('user_id').join(df.set_index('user_id'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630000</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 06:26:06.548941</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630001</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-16 03:16:42.560309</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630002</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 19:20:56.438330</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630003</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-12 10:09:31.510471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630004</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-18 20:23:58.824994</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "630000       US  2017-01-19 06:26:06.548941  treatment     new_page   \n",
       "630001       US  2017-01-16 03:16:42.560309  treatment     new_page   \n",
       "630002       US  2017-01-19 19:20:56.438330    control     old_page   \n",
       "630003       US  2017-01-12 10:09:31.510471  treatment     new_page   \n",
       "630004       US  2017-01-18 20:23:58.824994  treatment     new_page   \n",
       "\n",
       "         converted  intercept  ab_page  \n",
       "user_id                                 \n",
       "630000           0          1        1  \n",
       "630001           1          1        1  \n",
       "630002           0          1        0  \n",
       "630003           0          1        1  \n",
       "630004           0          1        1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview df_new to confirm join\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'UK', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for all unique country values in df_new\n",
    "df_new['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630000</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 06:26:06.548941</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630001</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-16 03:16:42.560309</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630002</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 19:20:56.438330</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630003</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-12 10:09:31.510471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630004</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-18 20:23:58.824994</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "630000       US  2017-01-19 06:26:06.548941  treatment     new_page   \n",
       "630001       US  2017-01-16 03:16:42.560309  treatment     new_page   \n",
       "630002       US  2017-01-19 19:20:56.438330    control     old_page   \n",
       "630003       US  2017-01-12 10:09:31.510471  treatment     new_page   \n",
       "630004       US  2017-01-18 20:23:58.824994  treatment     new_page   \n",
       "\n",
       "         converted  intercept  ab_page  CA  UK  US  \n",
       "user_id                                             \n",
       "630000           0          1        1   0   0   1  \n",
       "630001           1          1        1   0   0   1  \n",
       "630002           0          1        0   0   0   1  \n",
       "630003           0          1        1   0   0   1  \n",
       "630004           0          1        1   0   0   1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create intercept and the necessary dummy variables\n",
    "df_new['intercept'] = 1\n",
    "df_new[['CA', 'UK', 'US']] = pd.get_dummies(df_new['country'])\n",
    "\n",
    "# confirm dummy variables\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# create and run the model, then store the results\n",
    "log_mod_2 = sm.Logit(df_new['converted'], df_new[['intercept', 'CA', 'UK']])\n",
    "\n",
    "results2 = log_mod_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 02 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:06:37</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9967</td> <td>    0.007</td> <td> -292.314</td> <td> 0.000</td> <td>   -2.010</td> <td>   -1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.746</td> <td> 0.456</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 02 Apr 2019   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        16:06:37   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9967      0.007   -292.314      0.000      -2.010      -1.983\n",
       "CA            -0.0408      0.027     -1.518      0.129      -0.093       0.012\n",
       "UK             0.0099      0.013      0.746      0.456      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display model results\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high p-values (greater than 0.05) associated with each of the country variables in our model, it does NOT appear that country has a significant impact on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run a logistic regression with ab_page and country of residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# create and run the model, then store the results\n",
    "log_mod_3 = sm.Logit(df_new['converted'], df_new[['intercept', 'ab_page', 'CA', 'UK']])\n",
    "\n",
    "results3 = log_mod_3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 02 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:06:42</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 02 Apr 2019   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        16:06:42   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display model results\n",
    "results3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has not been a significant change in the model. Due to the high p-values (greater than 0.05) associated with the ab_page variable and each of the country variables in our model, it does NOT appear that ab_page and country together has a significant impact on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outro'></a>\n",
    "## Outro\n",
    "\n",
    "Congratulations on completing the project! \n",
    "\n",
    "### Gather Submission Materials\n",
    "\n",
    "Once you are satisfied with the status of your Notebook, you should save it in a format that will make it easy for others to read. You can use the __File -> Download as -> HTML (.html)__ menu to save your notebook as an .html file. If you are working locally and get an error about \"No module name\", then open a terminal and try installing the missing module using `pip install <module_name>` (don't include the \"<\" or \">\" or any words following a period in the module name).\n",
    "\n",
    "You will submit both your original Notebook and an HTML or PDF copy of the Notebook for review. There is no need for you to include any data files with your submission. If you made reference to other websites, books, and other resources to help you in solving tasks in the project, make sure that you document them. It is recommended that you either add a \"Resources\" section in a Markdown cell at the end of the Notebook report, or you can include a `readme.txt` file documenting your sources.\n",
    "\n",
    "### Submit the Project\n",
    "\n",
    "When you're ready, click on the \"Submit Project\" button to go to the project submission page. You can submit your files as a .zip archive or you can link to a GitHub repository containing your project files. If you go with GitHub, note that your submission will be a snapshot of the linked repository at time of submission. It is recommended that you keep each project in a separate repository to avoid any potential confusion: if a reviewer gets multiple folders representing multiple projects, there might be confusion regarding what project is to be evaluated.\n",
    "\n",
    "It can take us up to a week to grade the project, but in most cases it is much faster. You will get an email once your submission has been reviewed. If you are having any problems submitting your project or wish to check on the status of your submission, please email us at dataanalyst-project@udacity.com. In the meantime, you should feel free to continue on with your learning journey by beginning the next module in the program."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
